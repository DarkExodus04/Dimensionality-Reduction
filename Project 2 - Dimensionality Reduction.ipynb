{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4577a5d4",
   "metadata": {},
   "source": [
    "# Project 2 - Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c48d26f",
   "metadata": {},
   "source": [
    "In this project, you will work with a custom handwritten character dataset. You will implement dimensionality reduction and manifold learning techniques for visualization and subsequent classification tasks to report on a set of questions.\n",
    "\n",
    "The goal of this assignment include:\n",
    "\n",
    "1. Dataset visualization and interpretability via dimensionality reduction\n",
    "2. Implement dimensionality reduction techniques with ```scikit-learn```\n",
    "3. Carry out experiments to select best subspace projections\n",
    "4. Design pipelines for hyperparameter tuning and model selection\n",
    "5. Implement performance evaluation metrics and evaluate results\n",
    "6. Report observations, propose business-centric solutions and propose mitigating strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb484cc",
   "metadata": {},
   "source": [
    "## Deliverables\n",
    "\n",
    "As part of this project, you should deliver the following materials:\n",
    "\n",
    "1. [**4-page IEEE-format paper**](https://www.ieee.org/conferences/publishing/templates.html). Write a paper with no more than 4 pages addressing the questions posed below. When writing this report, consider a business-oriented person as your reader (e.g. your PhD advisor, your internship manager, etc.). Tell *the story* for each datasets' goal and propose solutions by addressing (at least) the questions posed below.\n",
    "\n",
    "2. **Python Code**. Create two separate Notebooks: (1) \"training.ipynb\" used for training and hyperparameter tuning, (2) \"test.ipynb\" for evaluating the final trained model in the test set. The \"test.ipynb\" should load all trained objects and simply evaluate the performance. So don't forget to **push the trained models** to your repository to allow us to run it.\n",
    "\n",
    "All of your code should run without any errors and be well-documented. \n",
    "\n",
    "3. **README.md file**. Edit the readme.md file in your repository and how to use your code. If there are user-defined parameters, your readme.md file must clearly indicate so and demonstrate how to use your code. **Consider the case where the user wants to utilize your code to run on a different test set. Indicate in your readme.md file how this can be achieved.**\n",
    "\n",
    "This is an **individual assignment**. \n",
    "\n",
    "These deliverables are **due Monday, November 14 @ 11:59pm**. Late submissions will not be accepted, so please plan accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04efb838",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af17a9",
   "metadata": {},
   "source": [
    "# About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dc2f64",
   "metadata": {},
   "source": [
    "The training dataset is saved as a ```numpy``` array and contains a total of 6720 images from 10 classes. Each image is in grayscale and of size $300\\times 300$. The 10 classes and its label encoding are:\n",
    "\n",
    "| Character | a | b | c | d | e | f | g | h | $ | # |\n",
    "| ----      | --| --| --| --| --| --| --| --| --| --|\n",
    "| Label     |  0| 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', '$', '#']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c11215",
   "metadata": {},
   "source": [
    "Let's visualize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')\n",
    "\n",
    "# Loading Training Data\n",
    "X_train = np.load('data_train.npy').T\n",
    "t_train = np.load('labels_train.npy')\n",
    "\n",
    "print(X_train.shape, t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece7b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting number samples per class\n",
    "vals, counts = np.unique(t_train, return_counts=True)\n",
    "\n",
    "plt.bar(vals, counts)\n",
    "plt.xticks(range(10),range(10))\n",
    "plt.xlabel('Classes',size=20)\n",
    "plt.ylabel('# Samples per Class', size=20)\n",
    "plt.title('Training Data (Total = '+str(X_train.shape[1])+' samples)',size=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a27a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Displaying some random examples per class\n",
    "\n",
    "for i in range(0,10):\n",
    "    rnd_sample = npr.permutation(np.where(t_train==i)[0])\n",
    "    fig=plt.figure(figsize=(15,15))\n",
    "    for j in range(25):\n",
    "        fig.add_subplot(5,5,j+1)\n",
    "        plt.imshow(X_train[rnd_sample[j],:].reshape((300,300)),cmap='gray')\n",
    "        plt.axis('off');plt.title('Class '+str(int(t_train[rnd_sample[j]])),size=15)\n",
    "    plt.show()\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144a60f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf5178",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717807c3",
   "metadata": {},
   "source": [
    "1. Implement Recursive Feature Elimination (RFE) to select the subset of features. Experiment with at least 2 different estimators. \n",
    "\n",
    "    * Identify which pixels are selected and display mask examples from the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76303657",
   "metadata": {},
   "source": [
    "2. Implement Principal Component Analysis (PCA) to select the number of components that explain at least 90% of the explained variance. Train a classifier on the original dataset and the reduced dataset.\n",
    "    * Was training faster using the reduced dataset?\n",
    "    * Compare performances.\n",
    "    * Visualize the top 10 eigenvectors. Discuss what they represent.\n",
    "    * Visualize examples of image reconstruction from PCA projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c067002",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac064127",
   "metadata": {},
   "source": [
    "#### Question 3 is required for completion for the EEL 5934 section only. Individuals in EEL 4930 are welcome to solve these tasks but no extra credit will be credited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc21d6b",
   "metadata": {},
   "source": [
    "3. Use Fisher's Linear Discriminant Analysis (LDA) and t-SNE to reduce the dataset to 2-dimensions and visualize it.\n",
    "    * Visualize the dataset, be sure to color-code each point to its corresponding target label.\n",
    "    * How many features would you select? Why?\n",
    "    * Visualize and compare the 2-dimensional projections with PCA. Discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc69f43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad630a4",
   "metadata": {},
   "source": [
    "4. Implement at least 3 manifold learning algorithms for reducing the dimensionality of the feature space. Utilize the new lower-dimensional feature space to build a classifier.\n",
    "\n",
    "    * Which manifold learning algorithm would you select?\n",
    "    \n",
    "    * Visualize and interpret what the first 2 dimensions in the manifold learning algorithm you train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b9936",
   "metadata": {},
   "source": [
    "### Test Function\n",
    "\n",
    "For the test notebook, you will report performance in the test set which contains 2880 images of size $300\\times 300$, also saved as a ```numpy``` array of size $90000\\times 2880$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e30145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Test Data\n",
    "X_test = np.load('data_test.npy').T\n",
    "t_test = np.load('labels_test.npy')\n",
    "\n",
    "print(X_test.shape, t_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2074b",
   "metadata": {},
   "source": [
    "Your Notebook should include:\n",
    "\n",
    "1. Loading trained models from problems 1-4, and apply transformations to the test set. \n",
    "\n",
    "2. For problems 2 and 4, report on the standard performance measures of classification. Discuss and present your results within the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bc40d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66027c2c",
   "metadata": {},
   "source": [
    "# Submit Your Solution\n",
    "\n",
    "Confirm that you've successfully completed the assignment.\n",
    "\n",
    "Along with the Notebook, include a PDF of the notebook with your solutions.\n",
    "\n",
    "```add``` and ```commit``` the final version of your work, and ```push``` your code to your GitHub repository.\n",
    "\n",
    "Submit the URL of your GitHub Repository as your assignment submission on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa2d31e",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
